{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------\n",
        "# IITB EdTech Internship 2025 – Problem ID 7\n",
        "# STEP 5: Deep Gaze Modeling & Validation\n",
        "# --------------------------------------------------------------\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 0. Mount & Imports\n",
        "# --------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd, numpy as np, os, cv2, logging, json, random\n",
        "from pathlib import Path\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 1. CONFIG\n",
        "# --------------------------------------------------------------\n",
        "CLEAN_ROOT = Path(\"/content/results/cleaned\")\n",
        "METRICS_ROOT = CLEAN_ROOT / \"metrics\"\n",
        "MODEL_ROOT = CLEAN_ROOT / \"models\"\n",
        "MODEL_ROOT.mkdir(exist_ok=True)\n",
        "\n",
        "FDM_CANVAS_DIR = METRICS_ROOT / \"fdm_canvas\"\n",
        "IMG_ROOT = Path(\"/content/data/stimuli\")  # UPDATE: your actual image folder\n",
        "FIX_CANVAS = CLEAN_ROOT / \"fixations_canvas.csv\"\n",
        "\n",
        "LOG_OUT = MODEL_ROOT / \"05_step5.log\"\n",
        "logging.basicConfig(filename=LOG_OUT, level=logging.INFO,\n",
        "                    format=\"%(asctime)s | %(levelname)s | %(message)s\")\n",
        "log = logging.getLogger()\n",
        "log.info(\"=== STEP 5 STARTED ===\")\n",
        "print(\"STEP 5 – Deep Gaze Modeling & Validation\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. Load Stimulus List & Split\n",
        "# --------------------------------------------------------------\n",
        "fix_canvas = pd.read_csv(FIX_CANVAS)\n",
        "stim_list = fix_canvas[['pid','qid']].drop_duplicates()\n",
        "\n",
        "# Train/val split by stimulus (80/20)\n",
        "train_stim, val_stim = train_test_split(stim_list, test_size=0.2, random_state=42, stratify=stim_list.merge(fix_canvas[['pid','qid','difficulty']].drop_duplicates(), on=['pid','qid'])['difficulty'])\n",
        "\n",
        "train_stim.to_csv(MODEL_ROOT / \"train_stimuli.csv\", index=False)\n",
        "val_stim.to_csv(MODEL_ROOT / \"val_stimuli.csv\", index=False)\n",
        "\n",
        "log.info(f\"Split: {len(train_stim)} train, {len(val_stim)} val stimuli\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. Dataset Class\n",
        "# --------------------------------------------------------------\n",
        "class EyeGazeDataset(Dataset):\n",
        "    def __init__(self, stim_df, img_root, fdm_dir, canvas_size=1024, sigma=40):\n",
        "        self.stim_df = stim_df\n",
        "        self.img_root = Path(img_root)\n",
        "        self.fdm_dir = Path(fdm_dir)\n",
        "        self.canvas_size = canvas_size\n",
        "        self.sigma = sigma\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self): return len(self.stim_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.stim_df.iloc[idx]\n",
        "        pid, qid = row['pid'], row['qid']\n",
        "        img_path = self.img_root / f\"P{pid:02d}_Q{qid}.jpg\"  # UPDATE extension if needed\n",
        "        fdm_path = self.fdm_dir / f\"P{pid:02d}_Q{qid}.npy\"\n",
        "\n",
        "        # Load image\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None: raise FileNotFoundError(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img_tensor = self.transform(img)\n",
        "\n",
        "        # Load ground-truth FDM\n",
        "        fdm = np.load(fdm_path)\n",
        "        fdm = cv2.resize(fdm, (self.canvas_size, self.canvas_size))\n",
        "        if fdm.sum() > 0: fdm /= fdm.sum()\n",
        "        fdm_tensor = torch.tensor(fdm, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return img_tensor, fdm_tensor, pid, qid\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. Baselines\n",
        "# --------------------------------------------------------------\n",
        "print(\"4. Building Baselines...\")\n",
        "\n",
        "def center_bias(canvas_size=1024, sigma=200):\n",
        "    x = np.linspace(0, canvas_size-1, canvas_size)\n",
        "    y = np.linspace(0, canvas_size-1, canvas_size)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    center_x, center_y = canvas_size // 2, canvas_size // 2\n",
        "    cb = np.exp(-((X - center_x)**2 + (Y - center_y)**2) / (2 * sigma**2))\n",
        "    cb /= cb.sum()\n",
        "    return cb\n",
        "\n",
        "CB_MAP = center_bias()\n",
        "np.save(MODEL_ROOT / \"center_bias.npy\", CB_MAP)\n",
        "\n",
        "def blur_baseline(fdm_native):\n",
        "    return gaussian_filter(fdm_native, sigma=80)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. DeepGaze II Model (Pretrained + Fine-tune)\n",
        "# --------------------------------------------------------------\n",
        "print(\"5. Loading & Fine-tuning DeepGaze II...\")\n",
        "\n",
        "!pip install -q deepgaze\n",
        "\n",
        "from deepgaze import DeepGazeII\n",
        "\n",
        "# Load pretrained model\n",
        "model = DeepGazeII(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Freeze all but last layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.centerbias_layer.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Fine-tune setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "\n",
        "train_dataset = EyeGazeDataset(train_stim, IMG_ROOT, FDM_CANVAS_DIR)\n",
        "val_dataset = EyeGazeDataset(val_stim, IMG_ROOT, FDM_CANVAS_DIR)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 6. Training Loop\n",
        "# --------------------------------------------------------------\n",
        "print(\"6. Fine-tuning DeepGaze II...\")\n",
        "\n",
        "EPOCHS = 10\n",
        "best_val_loss = float('inf')\n",
        "history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for imgs, fdms, _, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
        "        imgs, fdms = imgs.to(device), fdms.to(device)\n",
        "        log_pred = model(imgs).log()\n",
        "        loss = criterion(log_pred, fdms)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for imgs, fdms, _, _ in val_loader:\n",
        "            imgs, fdms = imgs.to(device), fdms.to(device)\n",
        "            log_pred = model(imgs).log()\n",
        "            loss = criterion(log_pred, fdms)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_train = train_loss / len(train_loader)\n",
        "    avg_val = val_loss / len(val_loader)\n",
        "    history.append({'epoch': epoch+1, 'train_loss': avg_train, 'val_loss': avg_val})\n",
        "\n",
        "    if avg_val < best_val_loss:\n",
        "        best_val_loss = avg_val\n",
        "        torch.save(model.state_dict(), MODEL_ROOT / \"deepgaze_finetuned.pth\")\n",
        "        log.info(f\"New best model saved at epoch {epoch+1}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train:.4f} | Val Loss: {avg_val:.4f}\")\n",
        "\n",
        "history_df = pd.DataFrame(history)\n",
        "history_df.to_csv(MODEL_ROOT / \"training_history.csv\", index=False)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 7. Evaluation Metrics (Same as STEP 4)\n",
        "# --------------------------------------------------------------\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "\n",
        "def similarity(m1, m2): return np.sum(np.sqrt(m1 * m2))\n",
        "def kl_div(p, q): return np.sum(p * np.log(p / (q + 1e-12) + 1e-12))\n",
        "def cc(m1, m2): return np.corrcoef(m1.ravel(), m2.ravel())[0,1]\n",
        "def nss(sal, pts):\n",
        "    sal_norm = (sal - sal.mean()) / (sal.std() + 1e-8)\n",
        "    return sal_norm[pts[:,1].astype(int), pts[:,0].astype(int)].mean()\n",
        "\n",
        "def auc_judd(sal, pts):\n",
        "    labels = np.zeros(sal.size, dtype=int)\n",
        "    idx = pts[:,1].astype(int) * 1024 + pts[:,0].astype(int)\n",
        "    labels[idx] = 1\n",
        "    sal_flat = sal.ravel() + np.random.rand(sal.size) * 1e-8\n",
        "    return roc_auc_score(labels, sal_flat)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 8. Run Inference & Evaluate\n",
        "# --------------------------------------------------------------\n",
        "print(\"8. Evaluating Models...\")\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_ROOT / \"deepgaze_finetuned.pth\"))\n",
        "model.eval()\n",
        "\n",
        "results = []\n",
        "eval_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_tensor, gt_fdm, pid, qid in tqdm(eval_loader, desc=\"Evaluating\"):\n",
        "        pid, qid = pid.item(), qid.item()\n",
        "        img_tensor = img_tensor.to(device)\n",
        "        pred = model(img_tensor).cpu().numpy().squeeze()\n",
        "        pred = cv2.resize(pred, (1024, 1024))\n",
        "        if pred.sum() > 0: pred /= pred.sum()\n",
        "\n",
        "        gt = gt_fdm.numpy().squeeze()\n",
        "        cb = CB_MAP.copy()\n",
        "\n",
        "        # Get fixations\n",
        "        fix = fix_canvas[(fix_canvas['pid']==pid) & (fix_canvas['qid']==qid)]\n",
        "        pts = fix[['x_canvas','y_canvas']].values.astype(int)\n",
        "\n",
        "        row = {\n",
        "            'pid': pid, 'qid': qid,\n",
        "            'difficulty': fix['difficulty'].iloc[0],\n",
        "            'SIM_emp': similarity(gt, pred),\n",
        "            'KL_emp': kl_div(gt, pred),\n",
        "            'CC_emp': cc(gt, pred),\n",
        "            'NSS_emp': nss(pred, pts),\n",
        "            'AUC_emp': auc_judd(pred, pts),\n",
        "            'SIM_cb': similarity(gt, cb),\n",
        "            'KL_cb': kl_div(gt, cb),\n",
        "            'CC_cb': cc(gt, cb),\n",
        "            'NSS_cb': nss(cb, pts),\n",
        "            'AUC_cb': auc_judd(cb, pts)\n",
        "        }\n",
        "        results.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(MODEL_ROOT / \"model_evaluation.csv\", index=False)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 9. Stratified Summary\n",
        "# --------------------------------------------------------------\n",
        "summary = results_df.groupby('difficulty').mean()\n",
        "summary.to_csv(MODEL_ROOT / \"summary_by_difficulty.csv\")\n",
        "log.info(f\"DeepGaze outperforms center-bias: NSS Δ = {summary['NSS_emp'].mean() - summary['NSS_cb'].mean():.3f}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 10. Visualizations\n",
        "# --------------------------------------------------------------\n",
        "VIS_DIR = MODEL_ROOT / \"visualizations\"\n",
        "VIS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Sample predictions\n",
        "sample = results_df.sample(3)\n",
        "for _, row in sample.iterrows():\n",
        "    pid, qid = row['pid'], row['qid']\n",
        "    img = cv2.cvtColor(cv2.imread(str(IMG_ROOT / f\"P{pid:02d}_Q{qid}.jpg\")), cv2.COLOR_BGR2RGB)\n",
        "    gt = np.load(FDM_CANVAS_DIR / f\"P{pid:02d}_Q{qid}.npy\")\n",
        "    gt = cv2.resize(gt, (1024, 1024)); gt /= gt.sum()\n",
        "    pred = model(transforms.ToTensor()(img).unsqueeze(0).to(device)).cpu().numpy().squeeze()\n",
        "    pred = cv2.resize(pred, (1024, 1024)); pred /= pred.sum()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    axes[0].imshow(img); axes[0].set_title(\"Stimulus\")\n",
        "    sns.heatmap(gt, ax=axes[1], cmap='viridis', cbar=True); axes[1].set_title(\"Empirical FDM\")\n",
        "    sns.heatmap(pred, ax=axes[2], cmap='viridis', cbar=True); axes[2].set_title(\"DeepGaze Pred\")\n",
        "    for ax in axes: ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(VIS_DIR / f\"pred_P{pid:02d}_Q{qid}.png\")\n",
        "    plt.close()\n",
        "\n",
        "# Performance bar plot\n",
        "plot_df = summary[['NSS_emp','NSS_cb']].reset_index().melt(id_vars='difficulty', var_name='Model', value_name='NSS')\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=plot_df, x='difficulty', y='NSS', hue='Model', order=['easy','medium','hard'])\n",
        "plt.title(\"NSS: DeepGaze vs Center-Bias by Difficulty\")\n",
        "plt.savefig(VIS_DIR / \"nss_comparison.png\")\n",
        "plt.close()\n",
        "\n",
        "log.info(f\"Visualizations → {VIS_DIR}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# FINAL SUMMARY\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\nSTEP 5 COMPLETE!\")\n",
        "print(f\"Outputs → {MODEL_ROOT}\")\n",
        "print(f\"   • deepgaze_finetuned.pth\")\n",
        "print(f\"   • model_evaluation.csv\")\n",
        "print(f\"   • summary_by_difficulty.csv\")\n",
        "print(f\"   • visualizations/ (preds + NSS plot)\")\n",
        "\n",
        "log.info(\"STEP 5 FINISHED\")"
      ],
      "metadata": {
        "id": "Uzgo5qMUMvJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}